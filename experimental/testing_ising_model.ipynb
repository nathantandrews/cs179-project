{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation AI Ising Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_COUNT: int = 1000          # Number of users\n",
    "MOVIE_COUNT: int = 250          # Number of movies\n",
    "C_VALUE: float = 0.045          # Regularization constant\n",
    "LIKED_REQUIREMENT: float = 4.0  # Minimum rating to classify movie as liked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import ssl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# pyGMs library\n",
    "import pyGMs as gm\n",
    "import pyGMs.ising\n",
    "import pyGMs.wmb\n",
    "\n",
    "# removes deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists.\n"
     ]
    }
   ],
   "source": [
    "dataset_url: str = \"https://files.grouplens.org/datasets/movielens/ml-latest.zip\"\n",
    "zip_file: str = \"ml-latest.zip\"\n",
    "extract_folder: str = \"ml-latest\"\n",
    "\n",
    "# Mac workaround (only if needed)\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "if not os.path.exists(extract_folder):\n",
    "    print(\"Downloading MovieLens dataset...\")\n",
    "    urllib.request.urlretrieve(dataset_url, zip_file)\n",
    "    print(\"Extracting...\")\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(\"Dataset already exists.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_HISTORY_FILENAME: str = \"run_history.log\"\n",
    "LABEL_WIDTH = 40\n",
    "VALUE_WIDTH = 20\n",
    "written_model_headers: set[str] = set()\n",
    "def log_run_header(user_count: int, movie_count: int, c_value: float, filename: str = RUN_HISTORY_FILENAME):\n",
    "    timestamp: str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"=\" * (LABEL_WIDTH + VALUE_WIDTH) + \"\\n\")\n",
    "        f.write(f\"{'u_count:':<{LABEL_WIDTH}}{user_count:>{VALUE_WIDTH}}\\n\")\n",
    "        f.write(f\"{'m_count:':<{LABEL_WIDTH}}{movie_count:>{VALUE_WIDTH}}\\n\")\n",
    "        f.write(f\"{'c_value:':<{LABEL_WIDTH}}{c_value:>{VALUE_WIDTH}.4f}\\n\")\n",
    "        f.write(f\"{'Run at:':<{LABEL_WIDTH}}{timestamp:>{VALUE_WIDTH}}\\n\")\n",
    "        f.write(\"-\" * (LABEL_WIDTH + VALUE_WIDTH) + \"\\n\")\n",
    "\n",
    "def save_run_data(model_type: str, output_dict: dict, filename=RUN_HISTORY_FILENAME):\n",
    "    with open(filename, \"a\") as f:\n",
    "        header = {\n",
    "                    \"independent\": \"Independent Model\", \n",
    "                    \"ising\": \"Ising Model\"\n",
    "                 }.get(model_type.lower(), \"Unknown Model\")\n",
    "        if model_type not in written_model_headers:\n",
    "            f.write(f\"{header}\\n\")\n",
    "            written_model_headers.add(model_type)\n",
    "        for key, value in output_dict.items():\n",
    "            formatted_value = f\"{value:.4f}\" if isinstance(value, float) else str(value)\n",
    "            f.write(f\"{key:<{LABEL_WIDTH}}{formatted_value:>{VALUE_WIDTH}}\\n\")\n",
    "\n",
    "log_run_header(USER_COUNT, MOVIE_COUNT, C_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ml-latest/ratings.csv')\n",
    "\n",
    "# Filter top users/movies\n",
    "top_users = ratings['userId'].value_counts().head(USER_COUNT).index\n",
    "top_movies = ratings['movieId'].value_counts().head(MOVIE_COUNT).index\n",
    "\n",
    "\n",
    "filtered = ratings[(ratings['userId'].isin(top_users)) & (ratings['movieId'].isin(top_movies))]\n",
    "pivot = filtered.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "# Binary matrix: 1 if liked (rating >= LIKED_REQUIREMENT), else 0\n",
    "X = (pivot >= LIKED_REQUIREMENT).astype(int).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv(os.path.join(extract_folder, 'movies.csv'))\n",
    "id_to_title = dict(zip(movies['movieId'], movies['title']))\n",
    "\n",
    "# Build a short label dictionary for visualization\n",
    "# short = {i: id_to_title[mid] for i, mid in enumerate(pivot.columns)}\n",
    "# print(short)\n",
    "\n",
    "Xtr, Xte = train_test_split(X, test_size=0.2, random_state=42)\n",
    "nMovies = Xtr.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent Model (trivial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Independent model Train LL: -155.09829868656539\n",
      "Independent model Test  LL: -155.68010474922153\n"
     ]
    }
   ],
   "source": [
    "pXi = np.mean(Xtr, axis=0)\n",
    "model0 = gm.GraphModel([gm.Factor([gm.Var(i, 2)], [1 - pXi[i], pXi[i]]) for i in range(nMovies)]) # type: ignore\n",
    "\n",
    "ind_train_ll = np.mean([model0.logValue(x) for x in Xtr])\n",
    "ind_test_ll = np.mean([model0.logValue(x) for x in Xte])\n",
    "\n",
    "save_run_data(\"independent\", {\"- Log-Likelihood (Train)\" : float(ind_train_ll), \n",
    "                              \"- Log-Likelihood (Test)\" : float(ind_test_ll)})\n",
    "\n",
    "print(\"Independent model Train LL:\", ind_train_ll)\n",
    "print(\"Independent model Test  LL:\", ind_test_ll)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of Ising Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average connectivity at C = 0.045 : 10.468\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "nbrs, th_ij, th_i = [None] * nMovies, [None] * nMovies, np.zeros((nMovies,))\n",
    "Xtmp = np.copy(Xtr)\n",
    "\n",
    "for i in range(nMovies):\n",
    "    Xtmp[:, i] = 0.\n",
    "    lr = LogisticRegression(penalty='l1', C=C_VALUE, solver='liblinear').fit(Xtmp, Xtr[:, i])\n",
    "    nbrs[i] = np.where(np.abs(lr.coef_) > 1e-6)[1]\n",
    "    th_ij[i] = lr.coef_[0, nbrs[i]] / 2.\n",
    "    th_i[i] = lr.intercept_ / 2.\n",
    "    Xtmp[:, i] = Xtr[:, i]\n",
    "\n",
    "average_connectivity = np.mean([len(nn) for nn in nbrs])\n",
    "std_dev_average_connectivity = np.std([len(nn) for nn in nbrs])\n",
    "\n",
    "save_run_data(\"ising\", {\"- Average Connectivity\" : f\"{average_connectivity:.4f} +/- {std_dev_average_connectivity:.4f}\"})\n",
    "\n",
    "print(\"Average connectivity at C =\", C_VALUE, \":\", average_connectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = [gm.Factor(gm.Var(i, 2), [-t, t]).exp() for i, t in enumerate(th_i)] # type: ignore\n",
    "for i in range(nMovies):\n",
    "    for j, n in enumerate(nbrs[i]):\n",
    "        scope = [gm.Var(i, 2), gm.Var(int(n), 2)]\n",
    "        t = th_ij[i][j]\n",
    "        factors.append(gm.Factor(scope, [[t, -t], [-t, t]]).exp()) # type: ignore\n",
    "\n",
    "model1 = gm.GraphModel(factors)\n",
    "model1.makeMinimal()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print mapping of movie indices to titles\n",
    "# print(\"Movie Index to Title Mapping:\")\n",
    "# print(\"-\" * 40)\n",
    "# for var in model1.vars:\n",
    "#     print(f\"Movie {var.label}: {short[var.label]}\")\n",
    "# print(\"-\" * 40)\n",
    "\n",
    "# Draw graph with numeric labels\n",
    "# short_labels = {var.label: var.label for var in model1.vars}\n",
    "# gm.drawMarkovGraph(model1, labels=short_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional(factor, i, x):\n",
    "    return factor.t[tuple(x[v] if v != i else slice(v.states) for v in factor.vars)]\n",
    "\n",
    "def pseudolikelihood(model, X):\n",
    "    LL = np.zeros(X.shape)\n",
    "    for i in range(X.shape[1]):  # for each variable (movie)\n",
    "        flist = model.factorsWith(i, copy=False)\n",
    "        for j in range(X.shape[0]):  # for each data point (user)\n",
    "            pXi = 1.\n",
    "            for f in flist:\n",
    "                pXi *= conditional(f, i, X[j])\n",
    "            LL[j, i] = np.log(pXi[X[j, i]] / pXi.sum()) # type: ignore\n",
    "    return LL.sum(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-likelihood (Train): -136.74686702930177\n",
      "Pseudo-likelihood (Test): -142.41073773488068\n"
     ]
    }
   ],
   "source": [
    "pseudolikelihood_tr: float = float(pseudolikelihood(model1, Xtr).mean())\n",
    "pseudolikelihood_te: float = float(pseudolikelihood(model1, Xte).mean())\n",
    "\n",
    "save_run_data(\"ising\", {\"- Pseudo-Likelihood (Train)\" : pseudolikelihood_tr, \n",
    "                        \"- Pseudo-Likelihood (Test)\" : pseudolikelihood_te})\n",
    "\n",
    "print(\"Pseudo-likelihood (Train):\", pseudolikelihood_tr)\n",
    "print(\"Pseudo-likelihood (Test):\", pseudolikelihood_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(model, Xobs):\n",
    "    m,n = Xobs.shape\n",
    "    Xhat = np.copy(Xobs)\n",
    "    for j in range(m):\n",
    "        x_obs = {i:Xobs[j,i] for i in range(n) if Xobs[j,i] >= 0}\n",
    "        x_unobs = [i for i in range(n) if Xobs[j,i] < 0]\n",
    "        cond = gm.GraphModel([f.condition(x_obs) for f in model.factorsWithAny(x_unobs)])\n",
    "        for x in cond.X:\n",
    "            if x.states == 0:\n",
    "                x.states = 1  # fix a bug in GraphModel behavior for missing vars...\n",
    "        jt = pyGMs.wmb.JTree(cond, weights=1e-6) # 0: for maximization\n",
    "        x_hat = jt.argmax()\n",
    "        for i in x_unobs: \n",
    "            Xhat[j,i] = x_hat[i]\n",
    "    return Xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of Xte to simulate missing values\n",
    "Xte_missing = np.copy(Xte)\n",
    "\n",
    "# Amount of test data that will be hidden\n",
    "missing_proportion = 0.2\n",
    "\n",
    "# Random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Boolean mask where True means that position is missing and apply it to Xte_missing\n",
    "mask = np.random.rand(*Xte.shape) < missing_proportion\n",
    "\n",
    "# Set the selected entries to a missing indicator\n",
    "Xte_missing[mask] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Slow!  (Constructing lots of conditional models...)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m Xte_hat = \u001b[43mimpute_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXte_missing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Compare the imputed values (Xte_hat) with the original true values (Xte)\u001b[39;00m\n\u001b[32m      5\u001b[39m error_rate = np.mean(Xte_hat[mask] != Xte[mask]) * \u001b[32m100\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mimpute_missing\u001b[39m\u001b[34m(model, Xobs)\u001b[39m\n\u001b[32m     10\u001b[39m         x.states = \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# fix a bug in GraphModel behavior for missing vars...\u001b[39;00m\n\u001b[32m     11\u001b[39m jt = pyGMs.wmb.JTree(cond, weights=\u001b[32m1e-6\u001b[39m) \u001b[38;5;66;03m# 0: for maximization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m x_hat = \u001b[43mjt\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m x_unobs: \n\u001b[32m     14\u001b[39m     Xhat[j,i] = x_hat[i]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nathan\\code\\school\\cs179\\cs179-project\\.venv\\Lib\\site-packages\\pyGMs\\wmb.py:712\u001b[39m, in \u001b[36mJTree.argmax\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute a maximizing argument of the junction tree.  Calls msgForward if not yet done.\"\"\"\u001b[39;00m\n\u001b[32m    711\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.forwardDone: \u001b[38;5;28mself\u001b[39m.msgForward()   \u001b[38;5;66;03m# or raise valueerror?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m712\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mJTree\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43massignBackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nathan\\code\\school\\cs179\\cs179-project\\.venv\\Lib\\site-packages\\pyGMs\\wmb.py:600\u001b[39m, in \u001b[36mWMB.assignBackward\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    598\u001b[39m         bel += mb.theta.condition(x)\n\u001b[32m    599\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m mb.children: bel += c.msgFwd.condition(x)\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m     x[X] = \u001b[43mbel\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nathan\\code\\school\\cs179\\cs179-project\\.venv\\Lib\\site-packages\\pyGMs\\factor.py:473\u001b[39m, in \u001b[36mFactor.argmax\u001b[39m\u001b[34m(self, evidence)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Find the argmax of the factor, with partial conditioning (as dict evidence[v]) if desired\u001b[39;00m\n\u001b[32m    469\u001b[39m \n\u001b[32m    470\u001b[39m \u001b[33;03mReturns a maximizing configuration of f(X|Xc=xc) as a tuple of states\u001b[39;00m\n\u001b[32m    471\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(evidence)==\u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mind2sub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m ax = \u001b[38;5;28mtuple\u001b[39m(evidence[v] \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m evidence \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.v)\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.v.ind2sub( \u001b[38;5;28mself\u001b[39m.t[ax].argmax() )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nathan\\code\\school\\cs179\\cs179-project\\.venv\\Lib\\site-packages\\pyGMs\\varset_py.py:60\u001b[39m, in \u001b[36mVarSet.ind2sub\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mind2sub\u001b[39m(\u001b[38;5;28mself\u001b[39m,idx):\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43munravel_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Slow!  (Constructing lots of conditional models...)\n",
    "Xte_hat = impute_missing(model1, Xte_missing)\n",
    "\n",
    "# Compare the imputed values (Xte_hat) with the original true values (Xte)\n",
    "error_rate = np.mean(Xte_hat[mask] != Xte[mask]) * 100\n",
    "\n",
    "save_run_data(\"ising\", {\"- Error Rate\" : f\"{error_rate:.4f}%\"})\n",
    "\n",
    "print(f\"Error Rate: {error_rate:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
