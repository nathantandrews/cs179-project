{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation AI Ising Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_COUNT: int = 1000          # Number of users\n",
    "MOVIE_COUNT: int = 250          # Number of movies\n",
    "C_VALUE: float = 0.045          # Regularization constant\n",
    "MINIMUM_RATING: float = 4.0  # Minimum rating to classify movie as liked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import ssl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib as p\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# pyGMs library\n",
    "import pyGMs as gm\n",
    "import pyGMs.ising\n",
    "import pyGMs.wmb\n",
    "\n",
    "# removes deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading MovieLens dataset...\n",
      "Extracting...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dataset_url: str = \"https://files.grouplens.org/datasets/movielens/ml-latest.zip\"\n",
    "zip_file: str = \"ml-latest.zip\"\n",
    "extract_folder: p.Path = p.Path(\"model/data\")\n",
    "\n",
    "# Mac workaround (only if needed)\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "if not os.path.exists(extract_folder):\n",
    "    print(\"Downloading MovieLens dataset...\")\n",
    "    urllib.request.urlretrieve(dataset_url, zip_file)\n",
    "    print(\"Extracting...\")\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        for member in zip_ref.namelist():\n",
    "            filename = os.path.basename(member)\n",
    "            if not filename:\n",
    "                continue  # skip directories\n",
    "            source = zip_ref.open(member)\n",
    "            target_path = os.path.join(extract_folder, filename)\n",
    "            with open(target_path, \"wb\") as target:\n",
    "                target.write(source.read())    \n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(\"Dataset already exists.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_HISTORY_FILENAME: str = \"run_history.log\"\n",
    "LABEL_WIDTH = 40\n",
    "VALUE_WIDTH = 20\n",
    "written_model_headers: set[str] = set()\n",
    "def log_run_header(user_count: int, movie_count: int, c_value: float, filename: str = RUN_HISTORY_FILENAME):\n",
    "    timestamp: str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"=\" * (LABEL_WIDTH + VALUE_WIDTH) + \"\\n\")\n",
    "        f.write(f\"{'u_count:':<{LABEL_WIDTH}}{user_count:>{VALUE_WIDTH}}\\n\")\n",
    "        f.write(f\"{'m_count:':<{LABEL_WIDTH}}{movie_count:>{VALUE_WIDTH}}\\n\")\n",
    "        f.write(f\"{'c_value:':<{LABEL_WIDTH}}{c_value:>{VALUE_WIDTH}.4f}\\n\")\n",
    "        f.write(f\"{'Run at:':<{LABEL_WIDTH}}{timestamp:>{VALUE_WIDTH}}\\n\")\n",
    "        f.write(\"-\" * (LABEL_WIDTH + VALUE_WIDTH) + \"\\n\")\n",
    "\n",
    "def save_run_data(model_type: str, output_dict: dict, filename=RUN_HISTORY_FILENAME):\n",
    "    with open(filename, \"a\") as f:\n",
    "        header = {\n",
    "                    \"independent\": \"Independent Model\", \n",
    "                    \"ising\": \"Ising Model\"\n",
    "                 }.get(model_type.lower(), \"Unknown Model\")\n",
    "        if model_type not in written_model_headers:\n",
    "            f.write(f\"{header}\\n\")\n",
    "            written_model_headers.add(model_type)\n",
    "        for key, value in output_dict.items():\n",
    "            formatted_value = f\"{value:.4f}\" if isinstance(value, float) else str(value)\n",
    "            f.write(f\"{key:<{LABEL_WIDTH}}{formatted_value:>{VALUE_WIDTH}}\\n\")\n",
    "\n",
    "log_run_header(USER_COUNT, MOVIE_COUNT, C_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ml-latest/ratings.csv')\n",
    "\n",
    "# Filter top users/movies\n",
    "top_users = ratings['userId'].value_counts().head(USER_COUNT).index\n",
    "top_movies = ratings['movieId'].value_counts().head(MOVIE_COUNT).index\n",
    "\n",
    "filtered = ratings[(ratings['userId'].isin(top_users)) & (ratings['movieId'].isin(top_movies))]\n",
    "pivot = filtered.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "# Binary matrix: 1 if liked (rating >= MINIMUM_RATING), else 0\n",
    "X = (pivot >= MINIMUM_RATING).astype(int).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv(os.path.join(extract_folder, 'movies.csv'))\n",
    "id_to_title = dict(zip(movies['movieId'], movies['title']))\n",
    "\n",
    "# Build a short label dictionary for visualization\n",
    "# short = {i: id_to_title[mid] for i, mid in enumerate(pivot.columns)}\n",
    "\n",
    "Xtr, Xte = train_test_split(X, test_size=0.2, random_state=42)\n",
    "nMovies = Xtr.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent Model (trivial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Independent model Train LL: -155.09829868656539\n",
      "Independent model Test  LL: -155.68010474922153\n"
     ]
    }
   ],
   "source": [
    "pXi = np.mean(Xtr, axis=0)\n",
    "model0 = gm.GraphModel([gm.Factor([gm.Var(i, 2)], [1 - pXi[i], pXi[i]]) for i in range(nMovies)]) # type: ignore\n",
    "\n",
    "ind_train_ll = np.mean([model0.logValue(x) for x in Xtr])\n",
    "ind_test_ll = np.mean([model0.logValue(x) for x in Xte])\n",
    "\n",
    "save_run_data(\"independent\", {\"- Log-Likelihood (Train)\" : float(ind_train_ll), \n",
    "                              \"- Log-Likelihood (Test)\" : float(ind_test_ll)})\n",
    "\n",
    "print(\"Independent model Train LL:\", ind_train_ll)\n",
    "print(\"Independent model Test  LL:\", ind_test_ll)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of Ising Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average connectivity at C = 0.045 : 10.456\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "nbrs, th_ij, th_i = [None] * nMovies, [None] * nMovies, np.zeros((nMovies,))\n",
    "Xtmp = np.copy(Xtr)\n",
    "\n",
    "for i in range(nMovies):\n",
    "    Xtmp[:, i] = 0.\n",
    "    lr = LogisticRegression(penalty='l1', C=C_VALUE, solver='liblinear').fit(Xtmp, Xtr[:, i])\n",
    "    nbrs[i] = np.where(np.abs(lr.coef_) > 1e-6)[1]\n",
    "    th_ij[i] = lr.coef_[0, nbrs[i]] / 2.\n",
    "    th_i[i] = lr.intercept_ / 2.\n",
    "    Xtmp[:, i] = Xtr[:, i]\n",
    "\n",
    "average_connectivity = np.mean([len(nn) for nn in nbrs])\n",
    "std_dev_average_connectivity = np.std([len(nn) for nn in nbrs])\n",
    "\n",
    "save_run_data(\"ising\", {\"- Average Connectivity\" : f\"{average_connectivity:.4f} +/- {std_dev_average_connectivity:.4f}\"})\n",
    "\n",
    "print(\"Average connectivity at C =\", C_VALUE, \":\", average_connectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = [gm.Factor(gm.Var(i, 2), [-t, t]).exp() for i, t in enumerate(th_i)] # type: ignore\n",
    "for i in range(nMovies):\n",
    "    for j, n in enumerate(nbrs[i]):\n",
    "        scope = [gm.Var(i, 2), gm.Var(int(n), 2)]\n",
    "        t = th_ij[i][j]\n",
    "        factors.append(gm.Factor(scope, [[t, -t], [-t, t]]).exp()) # type: ignore\n",
    "\n",
    "model1 = gm.GraphModel(factors)\n",
    "model1.makeMinimal()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print mapping of movie indices to titles\n",
    "# print(\"Movie Index to Title Mapping:\")\n",
    "# print(\"-\" * 40)\n",
    "# for var in model1.vars:\n",
    "#     print(f\"Movie {var.label}: {short[var.label]}\")\n",
    "# print(\"-\" * 40)\n",
    "\n",
    "# Draw graph with numeric labels\n",
    "# short_labels = {var.label: var.label for var in model1.vars}\n",
    "# gm.drawMarkovGraph(model1, labels=short_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional(factor, i, x):\n",
    "    return factor.t[tuple(x[v] if v != i else slice(v.states) for v in factor.vars)]\n",
    "\n",
    "def pseudolikelihood(model, X):\n",
    "    LL = np.zeros(X.shape)\n",
    "    for i in range(X.shape[1]):  # for each variable (movie)\n",
    "        flist = model.factorsWith(i, copy=False)\n",
    "        for j in range(X.shape[0]):  # for each data point (user)\n",
    "            pXi = 1.\n",
    "            for f in flist:\n",
    "                pXi *= conditional(f, i, X[j])\n",
    "            LL[j, i] = np.log(pXi[X[j, i]] / pXi.sum()) # type: ignore\n",
    "    return LL.sum(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-likelihood (Train): -136.74699397162544\n",
      "Pseudo-likelihood (Test): -142.41137286198756\n"
     ]
    }
   ],
   "source": [
    "pseudolikelihood_tr: float = float(pseudolikelihood(model1, Xtr).mean())\n",
    "pseudolikelihood_te: float = float(pseudolikelihood(model1, Xte).mean())\n",
    "\n",
    "save_run_data(\"ising\", {\"- Pseudo-Likelihood (Train)\" : pseudolikelihood_tr, \n",
    "                        \"- Pseudo-Likelihood (Test)\" : pseudolikelihood_te})\n",
    "\n",
    "print(\"Pseudo-likelihood (Train):\", pseudolikelihood_tr)\n",
    "print(\"Pseudo-likelihood (Test):\", pseudolikelihood_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(model, Xobs):\n",
    "    m,n = Xobs.shape\n",
    "    Xhat = np.copy(Xobs)\n",
    "    for j in range(m):\n",
    "        x_obs = {i:Xobs[j,i] for i in range(n) if Xobs[j,i] >= 0}\n",
    "        x_unobs = [i for i in range(n) if Xobs[j,i] < 0]\n",
    "        cond = gm.GraphModel([f.condition(x_obs) for f in model.factorsWithAny(x_unobs)])\n",
    "        for x in cond.X:\n",
    "            if x.states == 0:\n",
    "                x.states = 1  # fix a bug in GraphModel behavior for missing vars...\n",
    "        jt = pyGMs.wmb.JTree(cond, weights=1e-6) # 0: for maximization\n",
    "        x_hat = jt.argmax()\n",
    "        for i in x_unobs: \n",
    "            Xhat[j,i] = x_hat[i]\n",
    "    return Xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of Xte to simulate missing values\n",
    "Xte_missing = np.copy(Xte)\n",
    "\n",
    "# Amount of test data that will be hidden\n",
    "missing_proportion = 0.2\n",
    "\n",
    "# Random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Boolean mask where True means that position is missing and apply it to Xte_missing\n",
    "mask = np.random.rand(*Xte.shape) < missing_proportion\n",
    "\n",
    "# Set the selected entries to a missing indicator\n",
    "Xte_missing[mask] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate: 25.0125\n"
     ]
    }
   ],
   "source": [
    "# Slow!  (Constructing lots of conditional models...)\n",
    "Xte_hat = impute_missing(model1, Xte_missing)\n",
    "\n",
    "# Compare the imputed values (Xte_hat) with the original true values (Xte)\n",
    "error_rate = np.mean(Xte_hat[mask] != Xte[mask]) * 100\n",
    "\n",
    "save_run_data(\"ising\", {\"- Error Rate\" : f\"{error_rate:.4f}%\"})\n",
    "\n",
    "print(f\"Error Rate: {error_rate:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
