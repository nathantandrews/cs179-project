{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation AI Ising Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_COUNT: int = 1000          # Number of users\n",
    "MOVIE_COUNT: int = 250          # Number of movies\n",
    "C_VALUE: float = 0.045          # Regularization constant\n",
    "MINIMUM_RATING: float = 4.0  # Minimum rating to classify movie as liked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import ssl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib as p\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# pyGMs library\n",
    "import pyGMs as gm\n",
    "import pyGMs.ising\n",
    "import pyGMs.wmb\n",
    "\n",
    "# removes deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists.\n"
     ]
    }
   ],
   "source": [
    "dataset_url: str = \"https://files.grouplens.org/datasets/movielens/ml-latest.zip\"\n",
    "zip_file: str = \"ml-latest.zip\"\n",
    "extract_folder: p.Path = p.Path(\"ml-latest\")\n",
    "\n",
    "# Mac workaround (only if needed)\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "if not os.path.exists(extract_folder):\n",
    "    print(\"Downloading MovieLens dataset...\")\n",
    "    urllib.request.urlretrieve(dataset_url, zip_file)\n",
    "    print(\"Extracting...\")\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        for member in zip_ref.namelist():\n",
    "            filename = os.path.basename(member)\n",
    "            if not filename:\n",
    "                continue  # skip directories\n",
    "            source = zip_ref.open(member)\n",
    "            target_path = os.path.join(extract_folder, filename)\n",
    "            with open(target_path, \"wb\") as target:\n",
    "                target.write(source.read())    \n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(\"Dataset already exists.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_HISTORY_FILENAME: str = \"run_history.log\"\n",
    "LABEL_WIDTH = 40\n",
    "VALUE_WIDTH = 20\n",
    "written_model_headers: set[str] = set()\n",
    "def log_run_header(user_count: int, movie_count: int, c_value: float, filename: str = RUN_HISTORY_FILENAME):\n",
    "    timestamp: str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"=\" * (LABEL_WIDTH + VALUE_WIDTH) + \"\\n\")\n",
    "        f.write(f\"{'u_count:':<{LABEL_WIDTH}}{user_count:>{VALUE_WIDTH}}\\n\")\n",
    "        f.write(f\"{'m_count:':<{LABEL_WIDTH}}{movie_count:>{VALUE_WIDTH}}\\n\")\n",
    "        f.write(f\"{'c_value:':<{LABEL_WIDTH}}{c_value:>{VALUE_WIDTH}.4f}\\n\")\n",
    "        f.write(f\"{'Run at:':<{LABEL_WIDTH}}{timestamp:>{VALUE_WIDTH}}\\n\")\n",
    "        f.write(\"-\" * (LABEL_WIDTH + VALUE_WIDTH) + \"\\n\")\n",
    "\n",
    "def save_run_data(model_type: str, output_dict: dict, filename=RUN_HISTORY_FILENAME):\n",
    "    with open(filename, \"a\") as f:\n",
    "        header = {\n",
    "                    \"independent\": \"Independent Model\", \n",
    "                    \"ising\": \"Ising Model\"\n",
    "                 }.get(model_type.lower(), \"Unknown Model\")\n",
    "        if model_type not in written_model_headers:\n",
    "            f.write(f\"{header}\\n\")\n",
    "            written_model_headers.add(model_type)\n",
    "        for key, value in output_dict.items():\n",
    "            formatted_value = f\"{value:.4f}\" if isinstance(value, float) else str(value)\n",
    "            f.write(f\"{key:<{LABEL_WIDTH}}{formatted_value:>{VALUE_WIDTH}}\\n\")\n",
    "\n",
    "log_run_header(USER_COUNT, MOVIE_COUNT, C_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ml-latest/ratings.csv')\n",
    "\n",
    "# Filter top users/movies\n",
    "top_users = ratings['userId'].value_counts().head(USER_COUNT).index\n",
    "top_movies = ratings['movieId'].value_counts().head(MOVIE_COUNT).index\n",
    "\n",
    "filtered = ratings[(ratings['userId'].isin(top_users)) & (ratings['movieId'].isin(top_movies))]\n",
    "pivot = filtered.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "# Binary matrix: 1 if liked (rating >= MINIMUM_RATING), else 0\n",
    "X = (pivot >= MINIMUM_RATING).astype(int).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv(os.path.join(extract_folder, 'movies.csv'))\n",
    "id_to_title = dict(zip(movies['movieId'], movies['title']))\n",
    "\n",
    "# Build a short label dictionary for visualization\n",
    "# short = {i: id_to_title[mid] for i, mid in enumerate(pivot.columns)}\n",
    "\n",
    "Xtr, Xte = train_test_split(X, test_size=0.2, random_state=42)\n",
    "nMovies = Xtr.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent Model (trivial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Independent model Train LL: -155.09829868656539\n",
      "Independent model Test  LL: -155.68010474922153\n"
     ]
    }
   ],
   "source": [
    "pXi = np.mean(Xtr, axis=0)\n",
    "model0 = gm.GraphModel([gm.Factor([gm.Var(i, 2)], [1 - pXi[i], pXi[i]]) for i in range(nMovies)]) # type: ignore\n",
    "\n",
    "ind_train_ll = np.mean([model0.logValue(x) for x in Xtr])\n",
    "ind_test_ll = np.mean([model0.logValue(x) for x in Xte])\n",
    "\n",
    "save_run_data(\"independent\", {\"- Log-Likelihood (Train)\" : float(ind_train_ll), \n",
    "                              \"- Log-Likelihood (Test)\" : float(ind_test_ll)})\n",
    "\n",
    "print(\"Independent model Train LL:\", ind_train_ll)\n",
    "print(\"Independent model Test  LL:\", ind_test_ll)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of Ising Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average connectivity at C = 0.045 : 10.456\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "nbrs, th_ij, th_i = [None] * nMovies, [None] * nMovies, np.zeros((nMovies,))\n",
    "Xtmp = np.copy(Xtr)\n",
    "\n",
    "for i in range(nMovies):\n",
    "    Xtmp[:, i] = 0.\n",
    "    lr = LogisticRegression(penalty='l1', C=C_VALUE, solver='liblinear').fit(Xtmp, Xtr[:, i])\n",
    "    nbrs[i] = np.where(np.abs(lr.coef_) > 1e-6)[1]\n",
    "    th_ij[i] = lr.coef_[0, nbrs[i]] / 2.\n",
    "    th_i[i] = lr.intercept_ / 2.\n",
    "    Xtmp[:, i] = Xtr[:, i]\n",
    "\n",
    "average_connectivity = np.mean([len(nn) for nn in nbrs])\n",
    "std_dev_average_connectivity = np.std([len(nn) for nn in nbrs])\n",
    "\n",
    "save_run_data(\"ising\", {\"- Average Connectivity\" : f\"{average_connectivity:.4f} +/- {std_dev_average_connectivity:.4f}\"})\n",
    "\n",
    "print(\"Average connectivity at C =\", C_VALUE, \":\", average_connectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = [gm.Factor(gm.Var(i, 2), [-t, t]).exp() for i, t in enumerate(th_i)] # type: ignore\n",
    "for i in range(nMovies):\n",
    "    for j, n in enumerate(nbrs[i]):\n",
    "        scope = [gm.Var(i, 2), gm.Var(int(n), 2)]\n",
    "        t = th_ij[i][j]\n",
    "        factors.append(gm.Factor(scope, [[t, -t], [-t, t]]).exp()) # type: ignore\n",
    "\n",
    "model1 = gm.GraphModel(factors)\n",
    "model1.makeMinimal()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print mapping of movie indices to titles\n",
    "# print(\"Movie Index to Title Mapping:\")\n",
    "# print(\"-\" * 40)\n",
    "# for var in model1.vars:\n",
    "#     print(f\"Movie {var.label}: {short[var.label]}\")\n",
    "# print(\"-\" * 40)\n",
    "\n",
    "# Draw graph with numeric labels\n",
    "# short_labels = {var.label: var.label for var in model1.vars}\n",
    "# gm.drawMarkovGraph(model1, labels=short_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional(factor, i, x):\n",
    "    return factor.t[tuple(x[v] if v != i else slice(v.states) for v in factor.vars)]\n",
    "\n",
    "def pseudolikelihood(model, X):\n",
    "    LL = np.zeros(X.shape)\n",
    "    for i in range(X.shape[1]):  # for each variable (movie)\n",
    "        flist = model.factorsWith(i, copy=False)\n",
    "        for j in range(X.shape[0]):  # for each data point (user)\n",
    "            pXi = 1.\n",
    "            for f in flist:\n",
    "                pXi *= conditional(f, i, X[j])\n",
    "            LL[j, i] = np.log(pXi[X[j, i]] / pXi.sum()) # type: ignore\n",
    "    return LL.sum(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-likelihood (Train): -136.7481207341833\n",
      "Pseudo-likelihood (Test): -142.41302892673804\n"
     ]
    }
   ],
   "source": [
    "pseudolikelihood_tr: float = float(pseudolikelihood(model1, Xtr).mean())\n",
    "pseudolikelihood_te: float = float(pseudolikelihood(model1, Xte).mean())\n",
    "\n",
    "save_run_data(\"ising\", {\"- Pseudo-Likelihood (Train)\" : pseudolikelihood_tr, \n",
    "                        \"- Pseudo-Likelihood (Test)\" : pseudolikelihood_te})\n",
    "\n",
    "print(\"Pseudo-likelihood (Train):\", pseudolikelihood_tr)\n",
    "print(\"Pseudo-likelihood (Test):\", pseudolikelihood_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(model, Xobs):\n",
    "    m,n = Xobs.shape\n",
    "    Xhat = np.copy(Xobs)\n",
    "    for j in range(m):\n",
    "        x_obs = {i:Xobs[j,i] for i in range(n) if Xobs[j,i] >= 0}\n",
    "        x_unobs = [i for i in range(n) if Xobs[j,i] < 0]\n",
    "        cond = gm.GraphModel([f.condition(x_obs) for f in model.factorsWithAny(x_unobs)])\n",
    "        for x in cond.X:\n",
    "            if x.states == 0:\n",
    "                x.states = 1  # fix a bug in GraphModel behavior for missing vars...\n",
    "        jt = pyGMs.wmb.JTree(cond, weights=1e-6) # 0: for maximization\n",
    "        x_hat = jt.argmax()\n",
    "        for i in x_unobs: \n",
    "            Xhat[j,i] = x_hat[i]\n",
    "    return Xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of Xte to simulate missing values\n",
    "Xte_missing = np.copy(Xte)\n",
    "\n",
    "# Amount of test data that will be hidden\n",
    "missing_proportion = 0.2\n",
    "\n",
    "# Random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Boolean mask where True means that position is missing and apply it to Xte_missing\n",
    "mask = np.random.rand(*Xte.shape) < missing_proportion\n",
    "\n",
    "# Set the selected entries to a missing indicator\n",
    "Xte_missing[mask] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate: 25.0125\n"
     ]
    }
   ],
   "source": [
    "# Slow!  (Constructing lots of conditional models...)\n",
    "Xte_hat = impute_missing(model1, Xte_missing)\n",
    "\n",
    "# Compare the imputed values (Xte_hat) with the original true values (Xte)\n",
    "error_rate = np.mean(Xte_hat[mask] != Xte[mask]) * 100\n",
    "\n",
    "save_run_data(\"ising\", {\"- Error Rate\" : f\"{error_rate:.4f}%\"})\n",
    "\n",
    "print(f\"Error Rate: {error_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get most predictive movies of a single movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ids    = list(pivot.columns)           \n",
    "movie_titles = [id_to_title[mid] for mid in movie_ids] \n",
    "\n",
    "# 2) build full J from nbrs & th_ij (from Cell 7)\n",
    "J = np.zeros((nMovies, nMovies))\n",
    "for i in range(nMovies):\n",
    "    for k, j in enumerate(nbrs[i]):\n",
    "        J[i, j] = th_ij[i][k]\n",
    "\n",
    "# 3) symmetrize to get an undirected coupling matrix\n",
    "J_sym = 0.5 * (J + J.T)\n",
    "\n",
    "# sanity check\n",
    "assert J_sym.shape == (nMovies, nMovies)\n",
    "\n",
    "def get_predictive_movies(target_idx, J, movie_titles, top_k=10):\n",
    "    \"\"\"\n",
    "    Return the top_k movies whose ratings (via |J[target, :]|)\n",
    "    are most predictive of whether you'll like movie[target].\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    target_idx : int\n",
    "        Index of the movie of interest.\n",
    "    J : ndarray, shape (M, M)\n",
    "        Learned Ising interaction matrix.\n",
    "    movie_titles : list of str, length M\n",
    "        Titles aligned with J’s rows/cols.\n",
    "    top_k : int\n",
    "        Number of top movies to return.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List of tuples (title, coupling_strength), sorted by |coupling| descending.\n",
    "    \"\"\"\n",
    "    # extract couplings to all others\n",
    "    w = J[target_idx].copy()\n",
    "    # zero out self‐coupling\n",
    "    w[target_idx] = 0\n",
    "    # sort by absolute strength\n",
    "    idx_sorted = np.argsort(np.abs(w))[::-1]\n",
    "    top_idx = idx_sorted[:top_k]\n",
    "    return [(movie_titles[i], w[i]) for i in top_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 movies most predictive of liking 'Toy Story (1995)':\n",
      " 1. Toy Story 2 (1999)                       ➕ 0.7183\n",
      " 2. Finding Nemo (2003)                      ➕ 0.2473\n",
      " 3. Bug's Life, A (1998)                     ➕ 0.1356\n",
      " 4. Monsters, Inc. (2001)                    ➕ 0.0987\n",
      " 5. Princess Bride, The (1987)               ➕ 0.0623\n",
      " 6. Lion King, The (1994)                    ➕ 0.0526\n",
      " 7. Up (2009)                                ➕ 0.0460\n",
      " 8. Truman Show, The (1998)                  ➕ 0.0412\n",
      " 9. Big (1988)                               ➕ 0.0318\n",
      "10. Shawshank Redemption, The (1994)         ➕ 0.0271\n"
     ]
    }
   ],
   "source": [
    "target_idx = 0\n",
    "short = {i: id_to_title[mid] for i, mid in enumerate(pivot.columns)}\n",
    "\n",
    "top10 = get_predictive_movies(target_idx, J_sym, movie_titles, top_k=10)\n",
    "print(f\"Top 10 movies most predictive of liking {short[target_idx]!r}:\")\n",
    "for rank, (title, weight) in enumerate(top10, 1):\n",
    "    sign = \"➕\" if weight > 0 else \"➖\"\n",
    "    print(f\"{rank:2d}. {title:40s} {sign} {abs(weight):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a list of movies recommend a single movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_one_from_set(liked_idxs, movie_titles, J_sym):\n",
    "    \"\"\"\n",
    "    Given a list of movies the user likes, recommend the single movie\n",
    "    (not already in liked_titles) with the highest aggregate coupling.\n",
    "    \"\"\"\n",
    "    # aggregate score for each candidate j: sum of J_sym[j, i] over liked i\n",
    "    # we'll ignore negative influence by zeroing those out\n",
    "    # shape (M,)\n",
    "    agg = np.sum(np.where(J_sym[:, liked_idxs] > 0,\n",
    "                          J_sym[:, liked_idxs],\n",
    "                          0),\n",
    "                 axis=1)\n",
    "    \n",
    "    # exclude already liked\n",
    "    for i in liked_idxs:\n",
    "        agg[i] = -np.inf\n",
    "    \n",
    "    # pick the best\n",
    "    best_idx = np.argmax(agg)\n",
    "    return movie_titles[best_idx], agg[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Because you like:\n",
      "   • Jaws (1975)\n",
      "   • Jurassic Park (1993)\n",
      "   • Braveheart (1995)\n",
      "   • Taxi Driver (1976)\n",
      "   • Shawshank Redemption, The (1994)\n",
      "   • Toy Story (1995)\n",
      "\n",
      "→ we recommend: 'Toy Story 2 (1999)'  (score = 0.7407)\n"
     ]
    }
   ],
   "source": [
    "liked = [114, 50, 18, 19, 36, 0]\n",
    "rec_title, rec_score = recommend_one_from_set(liked, movie_titles, J_sym)\n",
    "print(\"Because you like:\")\n",
    "for t in liked:\n",
    "    print(\"   •\", short[t])\n",
    "print(f\"\\n→ we recommend: {rec_title!r}  (score = {rec_score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate the most predictive movies across all 1,000 users and 250 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 most frequently predictive movies:\n",
      "----------------------------------------\n",
      " 1. Toy Story (1995)                          72 occurrences\n",
      " 2. Jumanji (1995)                            46 occurrences\n",
      " 3. Heat (1995)                               40 occurrences\n",
      " 4. GoldenEye (1995)                          28 occurrences\n",
      " 5. Casino (1995)                             26 occurrences\n",
      " 6. Taxi Driver (1976)                        25 occurrences\n",
      " 7. Big (1988)                                23 occurrences\n",
      " 8. Sense and Sensibility (1995)              22 occurrences\n",
      " 9. Citizen Kane (1941)                       21 occurrences\n",
      "10. Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)  21 occurrences\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "target_idx = 1\n",
    "short = {i: id_to_title[mid] for i, mid in enumerate(pivot.columns)}\n",
    "aggregated = []\n",
    "\n",
    "for i in range(MOVIE_COUNT):\n",
    "    top10 = get_predictive_movies(i, J_sym, movie_titles, top_k=10)\n",
    "    # print(f\"Top 10 movies most predictive of liking {short[i]!r}:\")\n",
    "    for rank, (title, weight) in enumerate(top10, 1):\n",
    "      aggregated.append(title)\n",
    "\n",
    "print(\"\\nTop 10 most frequently predictive movies:\")\n",
    "print(\"-\" * 40)\n",
    "for rank, (title, count) in enumerate(Counter(aggregated).most_common(10), 1):\n",
    "    print(f\"{rank:2d}. {title:40s} {count:3d} occurrences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Toy Story (1995)\n",
      "1: Jumanji (1995)\n",
      "2: Heat (1995)\n",
      "3: GoldenEye (1995)\n",
      "4: Casino (1995)\n",
      "5: Sense and Sensibility (1995)\n",
      "6: Ace Ventura: When Nature Calls (1995)\n",
      "7: Get Shorty (1995)\n",
      "8: Leaving Las Vegas (1995)\n",
      "9: Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
      "10: Babe (1995)\n",
      "11: Dead Man Walking (1995)\n",
      "12: Clueless (1995)\n",
      "13: Seven (a.k.a. Se7en) (1995)\n",
      "14: Usual Suspects, The (1995)\n",
      "15: Mr. Holland's Opus (1995)\n",
      "16: Broken Arrow (1996)\n",
      "17: Happy Gilmore (1996)\n",
      "18: Braveheart (1995)\n",
      "19: Taxi Driver (1976)\n",
      "20: Birdcage, The (1996)\n",
      "21: Apollo 13 (1995)\n",
      "22: Batman Forever (1995)\n",
      "23: Crimson Tide (1995)\n",
      "24: Die Hard: With a Vengeance (1995)\n",
      "25: Net, The (1995)\n",
      "26: Waterworld (1995)\n",
      "27: Clerks (1994)\n",
      "28: Dumb & Dumber (Dumb and Dumber) (1994)\n",
      "29: Interview with the Vampire: The Vampire Chronicles (1994)\n",
      "30: Star Wars: Episode IV - A New Hope (1977)\n",
      "31: Natural Born Killers (1994)\n",
      "32: Outbreak (1995)\n",
      "33: Léon: The Professional (a.k.a. The Professional) (Léon) (1994)\n",
      "34: Pulp Fiction (1994)\n",
      "35: Stargate (1994)\n",
      "36: Shawshank Redemption, The (1994)\n",
      "37: Star Trek: Generations (1994)\n",
      "38: While You Were Sleeping (1995)\n",
      "39: Ace Ventura: Pet Detective (1994)\n",
      "40: Clear and Present Danger (1994)\n",
      "41: Forrest Gump (1994)\n",
      "42: Four Weddings and a Funeral (1994)\n",
      "43: Lion King, The (1994)\n",
      "44: Mask, The (1994)\n",
      "45: Speed (1994)\n",
      "46: True Lies (1994)\n",
      "47: Cliffhanger (1993)\n",
      "48: Firm, The (1993)\n",
      "49: Fugitive, The (1993)\n",
      "50: Jurassic Park (1993)\n",
      "51: Mrs. Doubtfire (1993)\n",
      "52: Philadelphia (1993)\n",
      "53: Schindler's List (1993)\n",
      "54: Sleepless in Seattle (1993)\n",
      "55: Blade Runner (1982)\n",
      "56: Nightmare Before Christmas, The (1993)\n",
      "57: Home Alone (1990)\n",
      "58: Ghost (1990)\n",
      "59: Aladdin (1992)\n",
      "60: Terminator 2: Judgment Day (1991)\n",
      "61: Dances with Wolves (1990)\n",
      "62: Batman (1989)\n",
      "63: Silence of the Lambs, The (1991)\n",
      "64: Beauty and the Beast (1991)\n",
      "65: Pretty Woman (1990)\n",
      "66: Fargo (1996)\n",
      "67: Mission: Impossible (1996)\n",
      "68: Rock, The (1996)\n",
      "69: Twister (1996)\n",
      "70: Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)\n",
      "71: Trainspotting (1996)\n",
      "72: Independence Day (a.k.a. ID4) (1996)\n",
      "73: Nutty Professor, The (1996)\n",
      "74: Godfather, The (1972)\n",
      "75: Rear Window (1954)\n",
      "76: Casablanca (1942)\n",
      "77: Wizard of Oz, The (1939)\n",
      "78: Citizen Kane (1941)\n",
      "79: 2001: A Space Odyssey (1968)\n",
      "80: Die Hard (1988)\n",
      "81: Willy Wonka & the Chocolate Factory (1971)\n",
      "82: Fish Called Wanda, A (1988)\n",
      "83: Monty Python's Life of Brian (1979)\n",
      "84: Reservoir Dogs (1992)\n",
      "85: E.T. the Extra-Terrestrial (1982)\n",
      "86: Top Gun (1986)\n",
      "87: Monty Python and the Holy Grail (1975)\n",
      "88: One Flew Over the Cuckoo's Nest (1975)\n",
      "89: Star Wars: Episode V - The Empire Strikes Back (1980)\n",
      "90: Princess Bride, The (1987)\n",
      "91: Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
      "92: Aliens (1986)\n",
      "93: Good, the Bad and the Ugly, The (Buono, il brutto, il cattivo, Il) (1966)\n",
      "94: Clockwork Orange, A (1971)\n",
      "95: Apocalypse Now (1979)\n",
      "96: Star Wars: Episode VI - Return of the Jedi (1983)\n",
      "97: Goodfellas (1990)\n",
      "98: Alien (1979)\n",
      "99: Psycho (1960)\n",
      "100: Blues Brothers, The (1980)\n",
      "101: Godfather: Part II, The (1974)\n",
      "102: Full Metal Jacket (1987)\n",
      "103: Amadeus (1984)\n",
      "104: Terminator, The (1984)\n",
      "105: Dead Poets Society (1989)\n",
      "106: Graduate, The (1967)\n",
      "107: Shining, The (1980)\n",
      "108: Stand by Me (1986)\n",
      "109: Groundhog Day (1993)\n",
      "110: Back to the Future (1985)\n",
      "111: Indiana Jones and the Last Crusade (1989)\n",
      "112: When Harry Met Sally... (1989)\n",
      "113: Star Trek: First Contact (1996)\n",
      "114: Jaws (1975)\n",
      "115: Jerry Maguire (1996)\n",
      "116: Liar Liar (1997)\n",
      "117: Austin Powers: International Man of Mystery (1997)\n",
      "118: Fifth Element, The (1997)\n",
      "119: Face/Off (1997)\n",
      "120: Men in Black (a.k.a. MIB) (1997)\n",
      "121: Contact (1997)\n",
      "122: Hunt for Red October, The (1990)\n",
      "123: L.A. Confidential (1997)\n",
      "124: Game, The (1997)\n",
      "125: Gattaca (1997)\n",
      "126: Truman Show, The (1998)\n",
      "127: Good Will Hunting (1997)\n",
      "128: Titanic (1997)\n",
      "129: Big Lebowski, The (1998)\n",
      "130: As Good as It Gets (1997)\n",
      "131: Armageddon (1998)\n",
      "132: There's Something About Mary (1998)\n",
      "133: Rain Man (1988)\n",
      "134: Breakfast Club, The (1985)\n",
      "135: Back to the Future Part II (1989)\n",
      "136: Back to the Future Part III (1990)\n",
      "137: Saving Private Ryan (1998)\n",
      "138: Indiana Jones and the Temple of Doom (1984)\n",
      "139: Beetlejuice (1988)\n",
      "140: Edward Scissorhands (1990)\n",
      "141: Life Is Beautiful (La Vita è bella) (1997)\n",
      "142: American History X (1998)\n",
      "143: Bug's Life, A (1998)\n",
      "144: Shakespeare in Love (1998)\n",
      "145: Office Space (1999)\n",
      "146: Lock, Stock & Two Smoking Barrels (1998)\n",
      "147: Matrix, The (1999)\n",
      "148: Mummy, The (1999)\n",
      "149: Star Wars: Episode I - The Phantom Menace (1999)\n",
      "150: Austin Powers: The Spy Who Shagged Me (1999)\n",
      "151: Run Lola Run (Lola rennt) (1998)\n",
      "152: American Pie (1999)\n",
      "153: Blair Witch Project, The (1999)\n",
      "154: Ghostbusters (a.k.a. Ghost Busters) (1984)\n",
      "155: Sixth Sense, The (1999)\n",
      "156: Airplane! (1980)\n",
      "157: Big (1988)\n",
      "158: American Beauty (1999)\n",
      "159: Total Recall (1990)\n",
      "160: Ferris Bueller's Day Off (1986)\n",
      "161: Fight Club (1999)\n",
      "162: Who Framed Roger Rabbit? (1988)\n",
      "163: Being John Malkovich (1999)\n",
      "164: Toy Story 2 (1999)\n",
      "165: Green Mile, The (1999)\n",
      "166: Gladiator (2000)\n",
      "167: Mission: Impossible II (2000)\n",
      "168: Chicken Run (2000)\n",
      "169: X-Men (2000)\n",
      "170: Almost Famous (2000)\n",
      "171: Meet the Parents (2000)\n",
      "172: Requiem for a Dream (2000)\n",
      "173: Charlie's Angels (2000)\n",
      "174: Crouching Tiger, Hidden Dragon (Wo hu cang long) (2000)\n",
      "175: Snatch (2000)\n",
      "176: Cast Away (2000)\n",
      "177: O Brother, Where Art Thou? (2000)\n",
      "178: Memento (2000)\n",
      "179: Shrek (2001)\n",
      "180: Donnie Darko (2001)\n",
      "181: Monsters, Inc. (2001)\n",
      "182: Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "183: Ocean's Eleven (2001)\n",
      "184: Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
      "185: Lord of the Rings: The Fellowship of the Ring, The (2001)\n",
      "186: Beautiful Mind, A (2001)\n",
      "187: Ice Age (2002)\n",
      "188: Spider-Man (2002)\n",
      "189: Star Wars: Episode II - Attack of the Clones (2002)\n",
      "190: Bourne Identity, The (2002)\n",
      "191: Minority Report (2002)\n",
      "192: Spirited Away (Sen to Chihiro no kamikakushi) (2001)\n",
      "193: Harry Potter and the Chamber of Secrets (2002)\n",
      "194: Lord of the Rings: The Two Towers, The (2002)\n",
      "195: Catch Me If You Can (2002)\n",
      "196: Pianist, The (2002)\n",
      "197: City of God (Cidade de Deus) (2002)\n",
      "198: X2: X-Men United (2003)\n",
      "199: Matrix Reloaded, The (2003)\n",
      "200: Finding Nemo (2003)\n",
      "201: Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "202: Lost in Translation (2003)\n",
      "203: Kill Bill: Vol. 1 (2003)\n",
      "204: Matrix Revolutions, The (2003)\n",
      "205: Lord of the Rings: The Return of the King, The (2003)\n",
      "206: Eternal Sunshine of the Spotless Mind (2004)\n",
      "207: Kill Bill: Vol. 2 (2004)\n",
      "208: Shrek 2 (2004)\n",
      "209: Harry Potter and the Prisoner of Azkaban (2004)\n",
      "210: Spider-Man 2 (2004)\n",
      "211: I, Robot (2004)\n",
      "212: Bourne Supremacy, The (2004)\n",
      "213: Shaun of the Dead (2004)\n",
      "214: Incredibles, The (2004)\n",
      "215: Sin City (2005)\n",
      "216: Star Wars: Episode III - Revenge of the Sith (2005)\n",
      "217: Batman Begins (2005)\n",
      "218: Harry Potter and the Goblet of Fire (2005)\n",
      "219: V for Vendetta (2006)\n",
      "220: Little Miss Sunshine (2006)\n",
      "221: Pan's Labyrinth (Laberinto del fauno, El) (2006)\n",
      "222: Departed, The (2006)\n",
      "223: Prestige, The (2006)\n",
      "224: Casino Royale (2006)\n",
      "225: Ratatouille (2007)\n",
      "226: 300 (2007)\n",
      "227: Bourne Ultimatum, The (2007)\n",
      "228: No Country for Old Men (2007)\n",
      "229: Juno (2007)\n",
      "230: Dark Knight, The (2008)\n",
      "231: Iron Man (2008)\n",
      "232: WALL·E (2008)\n",
      "233: Slumdog Millionaire (2008)\n",
      "234: Inglourious Basterds (2009)\n",
      "235: Up (2009)\n",
      "236: Hangover, The (2009)\n",
      "237: District 9 (2009)\n",
      "238: Avatar (2009)\n",
      "239: Shutter Island (2010)\n",
      "240: Inception (2010)\n",
      "241: Avengers, The (2012)\n",
      "242: Dark Knight Rises, The (2012)\n",
      "243: Django Unchained (2012)\n",
      "244: Wolf of Wall Street, The (2013)\n",
      "245: Interstellar (2014)\n",
      "246: Guardians of the Galaxy (2014)\n",
      "247: The Imitation Game (2014)\n",
      "248: Deadpool (2016)\n",
      "249: The Martian (2015)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for var in model1.vars:\n",
    "    print(f\"{var.label}: {short[var.label]}\")\n",
    "print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
